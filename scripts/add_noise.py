"""
Adiciona "Sujeira" aos Dados - Datathon Ribeirania
Torna os dados mais realistas e desafiadores

PROBLEMAS ADICIONADOS:
1. Valores ausentes (NaN)
2. Duplicatas
3. Outliers extremos
4. Dados inconsistentes
5. Erros de formata√ß√£o
6. Timestamps faltantes
7. Usernames com caracteres especiais
8. Posts vazios ou quebrados
"""

import pandas as pd
import numpy as np
from datetime import timedelta
import random
import warnings
warnings.filterwarnings('ignore')

print("=" * 70)
print(" ADICIONANDO 'SUJEIRA' AOS DADOS")
print("=" * 70)

# Configura√ß√µes de ru√≠do (porcentagens) que v√£o ser adicionadas
# Me baseiei em problemas reais de datasets p√∫blicos que j√° trabalhei em cima 
# As %s foram arbitr√°rias mas razoavelmente realistas para o tamanho dos datasets
# Como padr√£o, as %s podem ser ajustadas conforme necess√°rio

NOISE_CONFIG = {
    'missing_data_pct': 0.03,      # 3% de dados faltantes
    'duplicates_pct': 0.02,         # 2% de duplicatas
    'outliers_pct': 0.015,          # 1.5% de outliers
    'inconsistent_pct': 0.025,      # 2.5% de inconsist√™ncias
    'format_errors_pct': 0.02,      # 2% de erros de formato
}
# 1¬∞ Fun√ß√£o: suja a base de dados do Xister

def add_noise_to_xister(df):
    """Adiciona ru√≠do realista aos posts do Xister"""
    print("\nüì± Sujando dados do Xister...")
    
    df_dirty = df.copy()
    total_rows = len(df_dirty)
    
    # 1. VALORES AUSENTES (NaN)
    n_missing = int(total_rows * NOISE_CONFIG['missing_data_pct'])
    
    # Likes faltantes
    missing_likes = np.random.choice(df_dirty.index, size=n_missing//4, replace=False)
    df_dirty.loc[missing_likes, 'likes'] = np.nan
    
    # Sentiment faltante
    missing_sent = np.random.choice(df_dirty.index, size=n_missing//4, replace=False)
    df_dirty.loc[missing_sent, 'sentiment'] = np.nan
    
    # Username faltante
    missing_user = np.random.choice(df_dirty.index, size=n_missing//4, replace=False)
    df_dirty.loc[missing_user, 'username'] = np.nan
    
    # Text faltante ou vazio
    missing_text = np.random.choice(df_dirty.index, size=n_missing//4, replace=False)
    df_dirty.loc[missing_text, 'text'] = ''
    
    print(f"  ‚úì Adicionados {n_missing} valores ausentes")
    
    # 2. DUPLICATAS
    n_duplicates = int(total_rows * NOISE_CONFIG['duplicates_pct'])
    duplicate_indices = np.random.choice(df_dirty.index, size=n_duplicates, replace=False)
    duplicates = df_dirty.loc[duplicate_indices].copy()
    
    # Algumas duplicatas exatas
    df_dirty = pd.concat([df_dirty, duplicates.iloc[:n_duplicates//2]], ignore_index=True)
    
    # Algumas duplicatas com leve modifica√ß√£o
    duplicates_modified = duplicates.iloc[n_duplicates//2:].copy()
    duplicates_modified['likes'] = duplicates_modified['likes'] + np.random.randint(-5, 5, len(duplicates_modified))
    df_dirty = pd.concat([df_dirty, duplicates_modified], ignore_index=True)
    
    print(f"  ‚úì Adicionadas {n_duplicates} duplicatas")
    
    # 3. OUTLIERS EXTREMOS
    n_outliers = int(total_rows * NOISE_CONFIG['outliers_pct'])
    
    # Likes absurdos
    outlier_likes = np.random.choice(df_dirty.index, size=n_outliers//3, replace=False)
    df_dirty.loc[outlier_likes, 'likes'] = np.random.randint(500000, 10000000, len(outlier_likes))
    
    # Reposts negativos (erro)
    outlier_reposts = np.random.choice(df_dirty.index, size=n_outliers//3, replace=False)
    df_dirty.loc[outlier_reposts, 'reposts'] = np.random.randint(-100, -1, len(outlier_reposts))
    
    # Sentiment fora do range
    outlier_sent = np.random.choice(df_dirty.index, size=n_outliers//3, replace=False)
    df_dirty.loc[outlier_sent, 'sentiment'] = np.random.uniform(-5, 5, len(outlier_sent))
    
    print(f"  ‚úì Adicionados {n_outliers} outliers extremos")
    
    # 4. INCONSIST√äNCIAS
    n_inconsistent = int(total_rows * NOISE_CONFIG['inconsistent_pct'])
    
    # Posts com muito engagement mas sentiment negativo (suspeito)
    inconsistent_idx = np.random.choice(df_dirty.index, size=n_inconsistent//2, replace=False)
    df_dirty.loc[inconsistent_idx, 'sentiment'] = -0.8
    df_dirty.loc[inconsistent_idx, 'likes'] = np.random.randint(10000, 50000, len(inconsistent_idx))
    
    # Bots com muito engagement (suspeito)
    bot_mask = df_dirty['account_type'] == 'bot'
    suspicious_bots = df_dirty[bot_mask].sample(min(n_inconsistent//2, bot_mask.sum()))
    df_dirty.loc[suspicious_bots.index, 'likes'] = np.random.randint(5000, 20000, len(suspicious_bots))
    
    print(f"  ‚úì Adicionadas {n_inconsistent} inconsist√™ncias")
    
    # 5. ERROS DE FORMATO
    n_format_errors = int(total_rows * NOISE_CONFIG['format_errors_pct'])
    
    # Usernames com caracteres especiais estranhos
    format_errors = np.random.choice(df_dirty.index, size=n_format_errors//3, replace=False)
    for idx in format_errors:
        if pd.notna(df_dirty.loc[idx, 'username']):
            df_dirty.loc[idx, 'username'] = df_dirty.loc[idx, 'username'] + random.choice(['@@', '##', '$$', '!!', '??'])
    
    # Timestamps faltantes (convertidos para string quebrada)
    missing_ts = np.random.choice(df_dirty.index, size=n_format_errors//3, replace=False)
    df_dirty.loc[missing_ts, 'timestamp'] = 'ERRO'
    
    # Account type inv√°lido
    invalid_type = np.random.choice(df_dirty.index, size=n_format_errors//3, replace=False)
    df_dirty.loc[invalid_type, 'account_type'] = random.choice(['unknown', 'ERRO', '', 'NULL', 'deleted'])
    
    print(f"  ‚úì Adicionados {n_format_errors} erros de formato")
    
    # 6. EMBARALHA LINHAS
    df_dirty = df_dirty.sample(frac=1).reset_index(drop=True)
    
    print(f"\n  üìä Resumo Xister:")
    print(f"    - Linhas originais: {total_rows:,}")
    print(f"    - Linhas com ru√≠do: {len(df_dirty):,}")
    print(f"    - NaN em likes: {df_dirty['likes'].isna().sum()}")
    print(f"    - NaN em sentiment: {df_dirty['sentiment'].isna().sum()}")
    print(f"    - Posts vazios: {(df_dirty['text'] == '').sum()}")
    print(f"    - Usernames inv√°lidos: {df_dirty['username'].isna().sum()}")
    
    return df_dirty

# 2¬∞ Fun√ß√£o: suja as bases de dados de Crypto

def add_noise_to_crypto(df, coin_name):
    """Adiciona ru√≠do aos dados de crypto"""
    print(f"\nüí∞ Sujando dados de {coin_name}...")
    
    df_dirty = df.copy()
    total_rows = len(df_dirty)
    
    # 1. VALORES AUSENTES
    n_missing = int(total_rows * NOISE_CONFIG['missing_data_pct'])
    
    # Pre√ßo faltante
    missing_price = np.random.choice(df_dirty.index, size=n_missing//3, replace=False)
    df_dirty.loc[missing_price, 'price_usd'] = np.nan
    
    # Volume faltante
    missing_vol = np.random.choice(df_dirty.index, size=n_missing//3, replace=False)
    df_dirty.loc[missing_vol, 'volume_24h'] = np.nan
    
    # Market cap zerado
    missing_mc = np.random.choice(df_dirty.index, size=n_missing//3, replace=False)
    df_dirty.loc[missing_mc, 'market_cap'] = 0
    
    print(f"  ‚úì Adicionados {n_missing} valores ausentes")
    
    # 2. OUTLIERS
    n_outliers = int(total_rows * NOISE_CONFIG['outliers_pct'])
    
    # Pre√ßos absurdos
    outlier_price = np.random.choice(df_dirty.index, size=n_outliers//2, replace=False)
    df_dirty.loc[outlier_price, 'price_usd'] = df_dirty.loc[outlier_price, 'price_usd'] * np.random.uniform(50, 200, len(outlier_price))
    
    # Varia√ß√µes imposs√≠veis
    outlier_change = np.random.choice(df_dirty.index, size=n_outliers//2, replace=False)
    df_dirty.loc[outlier_change, 'price_change_pct'] = np.random.uniform(-99, 99, len(outlier_change))
    
    print(f"  ‚úì Adicionados {n_outliers} outliers")
    
    # 3. DUPLICATAS DE TIMESTAMP
    n_duplicates = int(total_rows * NOISE_CONFIG['duplicates_pct'])
    duplicate_indices = np.random.choice(df_dirty.index, size=n_duplicates, replace=False)
    duplicates = df_dirty.loc[duplicate_indices].copy()
    
    # Modifica levemente os pre√ßos mas mant√©m timestamp
    duplicates['price_usd'] = duplicates['price_usd'] * np.random.uniform(0.95, 1.05, len(duplicates))
    df_dirty = pd.concat([df_dirty, duplicates], ignore_index=True)
    
    print(f"  ‚úì Adicionadas {n_duplicates} duplicatas de timestamp")
    
    # 4. TIMESTAMPS QUEBRADOS
    n_format_errors = int(total_rows * NOISE_CONFIG['format_errors_pct'])
    format_errors = np.random.choice(df_dirty.index, size=n_format_errors, replace=False)
    df_dirty.loc[format_errors, 'timestamp'] = 'INVALID_DATE'
    
    print(f"  ‚úì Adicionados {n_format_errors} timestamps inv√°lidos")
    
    # 5. VALORES NEGATIVOS INV√ÅLIDOS
    n_negative = int(total_rows * 0.01)
    negative_idx = np.random.choice(df_dirty.index, size=n_negative, replace=False)
    df_dirty.loc[negative_idx, 'price_usd'] = -abs(df_dirty.loc[negative_idx, 'price_usd'])
    
    print(f"  ‚úì Adicionados {n_negative} pre√ßos negativos")
    
    # 6. EMBARALHA
    df_dirty = df_dirty.sample(frac=1).reset_index(drop=True)
    
    print(f"\n  üìä Resumo {coin_name}:")
    print(f"    - Linhas originais: {total_rows:,}")
    print(f"    - Linhas com ru√≠do: {len(df_dirty):,}")
    print(f"    - NaN em price: {df_dirty['price_usd'].isna().sum()}")
    print(f"    - NaN em volume: {df_dirty['volume_24h'].isna().sum()}")
    print(f"    - Pre√ßos negativos: {(df_dirty['price_usd'] < 0).sum()}")
    print(f"    - Timestamps inv√°lidos: {(df_dirty['timestamp'] == 'INVALID_DATE').sum()}")
    
    return df_dirty

# 3¬∞ Fun√ß√£o: suja a base de dados de Eventos

def add_noise_to_events(df):
    """Adiciona ru√≠do aos eventos"""
    print(f"\nüìÖ Sujando dados de Eventos...")
    
    df_dirty = df.copy()
    
    # 1. Datas duplicadas
    duplicate_event = df_dirty.sample(2)
    df_dirty = pd.concat([df_dirty, duplicate_event], ignore_index=True)
    
    # 2. Eventos com datas inv√°lidas
    invalid_dates = df_dirty.sample(2)
    df_dirty.loc[invalid_dates.index, 'date'] = 'DATA_INVALIDA'
    
    # 3. Intensidades fora do range
    invalid_intensity = df_dirty.sample(3)
    df_dirty.loc[invalid_intensity.index, 'impact_intensity'] = np.random.uniform(2, 10, len(invalid_intensity))
    
    # 4. Campos vazios
    empty_fields = df_dirty.sample(2)
    df_dirty.loc[empty_fields.index, 'event_description'] = ''
    
    print(f"  ‚úì Adicionados eventos duplicados, datas inv√°lidas e campos vazios")
    
    return df_dirty

# Fun√ß√£o Principal para cria√ß√£o e salvamento dos dados sujos
# Esses dados foram os que dei upload para a base de dados do Datathon, s√≥ troquei o nome, obviamente, pra n√£o deixar
# t√£o √≥bvio que as bases est√£o sujas e com outliers e erros

def main():
    print("\nCarregando dados limpos...")
    
    try:
        # Carrega dados limpos
        xister = pd.read_csv('xister_posts.csv', encoding='utf-8-sig')
        solana = pd.read_csv('solana_prices.csv', encoding='utf-8-sig')
        ribercoin = pd.read_csv('ribercoin_prices.csv', encoding='utf-8-sig')
        neuroncoin = pd.read_csv('neuroncoin_prices.csv', encoding='utf-8-sig')
        bonfimcoin = pd.read_csv('bonfimcoin_prices.csv', encoding='utf-8-sig')
        zephyrcoin = pd.read_csv('zephyrcoin_prices.csv', encoding='utf-8-sig')
        lunartoken = pd.read_csv('lunartoken_prices.csv', encoding='utf-8-sig')
        events = pd.read_csv('ribeirania_events.csv', encoding='utf-8-sig')
        
        print("‚úì Dados limpos carregados")
        
    except FileNotFoundError:
        print("‚ùå ERRO: Execute 'python main_generator.py' primeiro!")
        return
    
    print("\n" + "=" * 70)
    print(" ADICIONANDO RU√çDO")
    print("=" * 70)
    
    # Adiciona ru√≠do
    xister_dirty = add_noise_to_xister(xister)
    solana_dirty = add_noise_to_crypto(solana, 'Solana')
    ribercoin_dirty = add_noise_to_crypto(ribercoin, 'RiberCoin')
    neuroncoin_dirty = add_noise_to_crypto(neuroncoin, 'NeuronCoin')
    bonfimcoin_dirty = add_noise_to_crypto(bonfimcoin, 'BonfimCoin')
    zephyrcoin_dirty = add_noise_to_crypto(zephyrcoin, 'ZephyrCoin')
    lunartoken_dirty = add_noise_to_crypto(lunartoken, 'LunarToken')
    events_dirty = add_noise_to_events(events)
    
    # Salva vers√µes sujas
    print("\n" + "=" * 70)
    print(" SALVANDO DADOS SUJOS")
    print("=" * 70)
    
    xister_dirty.to_csv('xister_posts_dirty.csv', index=False, encoding='utf-8-sig')
    solana_dirty.to_csv('solana_prices_dirty.csv', index=False, encoding='utf-8-sig')
    ribercoin_dirty.to_csv('ribercoin_prices_dirty.csv', index=False, encoding='utf-8-sig')
    neuroncoin_dirty.to_csv('neuroncoin_prices_dirty.csv', index=False, encoding='utf-8-sig')
    bonfimcoin_dirty.to_csv('bonfimcoin_prices_dirty.csv', index=False, encoding='utf-8-sig')
    zephyrcoin_dirty.to_csv('zephyrcoin_prices_dirty.csv', index=False, encoding='utf-8-sig')
    lunartoken_dirty.to_csv('lunartoken_prices_dirty.csv', index=False, encoding='utf-8-sig')
    events_dirty.to_csv('ribeirania_events_dirty.csv', index=False, encoding='utf-8-sig')
    
    print("\n‚úì Dados sujos salvos (*_dirty.csv)")
    
    # Mant√©m originais como "gabarito"
    print("\nüí° Os arquivos originais foram mantidos como GABARITO")
    print("   Use os arquivos *_dirty.csv para o datathon!")
    
    print("\n" + "=" * 70)
    print(" ‚úÖ SUJEIRA ADICIONADA COM SUCESSO!")
    print("=" * 70)
    
    print("\nüìÇ Arquivos para Datathon (SUJOS):")
    print("  1. xister_posts_dirty.csv")
    print("  2. solana_prices_dirty.csv")
    print("  3. ribercoin_prices_dirty.csv")
    print("  4. neuroncoin_prices_dirty.csv")
    print("  5. bonfimcoin_prices_dirty.csv")
    print("  6. zephyrcoin_prices_dirty.csv")
    print("  7. lunartoken_prices_dirty.csv")
    print("  8. ribeirania_events_dirty.csv")
    
    print("\nüìÇ Arquivos LIMPOS (Gabarito - N√ÉO distribua!):")
    print("  - xister_posts.csv")
    print("  - *_prices.csv (originais)")
    
    print("\nüéØ Problemas adicionados:")
    print("  ‚úì Valores ausentes (NaN)")
    print("  ‚úì Duplicatas")
    print("  ‚úì Outliers extremos")
    print("  ‚úì Inconsist√™ncias nos dados")
    print("  ‚úì Erros de formata√ß√£o")
    print("  ‚úì Timestamps inv√°lidos")
    print("  ‚úì Usernames com caracteres especiais")
    print("  ‚úì Valores negativos inv√°lidos")
    print("  ‚úì Posts vazios")
    
    print("\nüí™ Desafios para os participantes:")
    print("  - Detectar e remover duplicatas")
    print("  - Tratar valores ausentes")
    print("  - Identificar e remover outliers")
    print("  - Corrigir timestamps inv√°lidos")
    print("  - Validar ranges de valores")
    print("  - Limpar usernames")
    print()

if __name__ == '__main__':
    main()